{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first pass, discretizing free text annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'DataFromFirstEmail/20190118_reading_specialists.csv'\n",
    ")\n",
    "obs_full = list(df.OBS)\n",
    "obs_short = [[y.strip() for y in x.lower().replace('$obs:', '').strip().split(';')] for x in obs_full]\n",
    "corpus = [x for y in obs_short for x in y if x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_short = [[y.strip() for y in x.lower().replace('$obs:', '').strip().split(';')] for x in obs_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rereads to self-correct'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [x for y in obs_short for x in y if x]\n",
    "corpus[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "ps = PorterStemmer()\n",
    "def preprocess(line):\n",
    "    return ' '.join([ps.stem(x) for x in line.strip().split()])\n",
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=preprocess)\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5).fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_to_cluster = {line: kmeans.predict(tfidf_vectorizer.transform([line]))[0] for line in corpus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for center in set(line_to_cluster.values()):\n",
    "    lines_with_center = [x for x in line_to_cluster if line_to_cluster[x] == center]\n",
    "    for line in lines_with_center:\n",
    "#         print('  -', line)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_(terms):\n",
    "    rolling = corpus\n",
    "    rolling_len = len(corpus)\n",
    "    for term in terms:\n",
    "        rolling = [x for x in rolling if term not in x]\n",
    "        new_len = len(rolling)\n",
    "        print(term, 'filtered out', rolling_len - new_len, '->', new_len, 'left')\n",
    "        rolling_len = new_len\n",
    "    for ln in rolling:\n",
    "        print(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expressi filtered out 100 -> 853 left\n",
      "fluen filtered out 29 -> 824 left\n",
      "phras filtered out 69 -> 755 left\n",
      "word by filtered out 24 -> 731 left\n",
      "word-by filtered out 2 -> 729 left\n",
      "intona filtered out 11 -> 718 left\n",
      "self-correct filtered out 73 -> 645 left\n",
      "self correct filtered out 4 -> 641 left\n",
      "accura filtered out 18 -> 623 left\n",
      "punctua filtered out 79 -> 544 left\n",
      "meaning filtered out 117 -> 427 left\n",
      "substitut filtered out 28 -> 399 left\n",
      "skip filtered out 5 -> 394 left\n",
      "miscu filtered out 12 -> 382 left\n",
      "vocabul filtered out 15 -> 367 left\n",
      "quiet filtered out 7 -> 360 left\n",
      "slow filtered out 8 -> 352 left\n",
      "decod filtered out 26 -> 326 left\n",
      "omit filtered out 14 -> 312 left\n",
      "omission filtered out 1 -> 311 left\n",
      "pronounc filtered out 3 -> 308 left\n",
      "pronunc filtered out 1 -> 307 left\n",
      "attack filtered out 10 -> 297 left\n",
      "mis filtered out 10 -> 287 left\n",
      "monotone filtered out 7 -> 280 left\n",
      "passage seems to be at independent reading level\n",
      "passage seems slightly easy for this student, may need a higher level text\n",
      "adequate pace and volume\n",
      "text seems below level for reader\n",
      "student pausing for new sentences\n",
      "student changing pitch when reading sentences ending in a question mark\n",
      "student placing emphasis on certain words\n",
      "stumbled on syntax in final sentence\n",
      "reads at an adequate rate\n",
      "student repeating certain words\n",
      "student inserting words 'in'\n",
      "student pausing to correctly sound out new words 'preservation'\n",
      "good reader in general\n",
      "struggled with syntax in last sentence\n",
      "student changing pitch when reading sentences ending in a question mark\n",
      "student adding -s to word that isn't plural 'lead'\n",
      "reads at a quick pace\n",
      "able to take apart multisyllabic words on the fly\n",
      "cross-checks efficiently\n",
      "text appears somewhat too easy for this student\n",
      "strong reader\n",
      "text seems easy\n",
      "good command of sight words and past tense verbs (-ed endings)\n",
      "leaves off -er ending on angler\n",
      "difficulty with the prefix un- in unusual\n",
      "able to take apart multisyllabic words in text\n",
      "noticing names of people\n",
      "strong start to the passage but loses stamina\n",
      "some evidence of taking apart longer words to solve them (hydroponic)\n",
      "reread part of a sentence\n",
      "strong reader\n",
      "text too difficult for this student\n",
      "attempts initial sounds but is not able to get medial sounds\n",
      "still appears to be at a short vowel sound level (cvc words)\n",
      "has some high frequency/sight words\n",
      "passage too hard\n",
      "noticing first letter, then guessing\n",
      "little background knowledge\n",
      "has some sight words\n",
      "text is too difficult\n",
      "guesses at words based on initial letters\n",
      "has some blending skills but needs more phonics\n",
      "good command of sight words\n",
      "student pausing for dialogue\n",
      "student repeating words 'sharp'\n",
      "text is too challenging for reader\n",
      "r-less\n",
      "difficulty with past tense verbs (-ed endings)\n",
      "student pausing in between words\n",
      "student reading very softly\n",
      "passage too difficult\n",
      "lacks confidence as a reader\n",
      "volume too low\n",
      "little background knowledge about the topic\n",
      "poor signal\n",
      "reads only known words\n",
      "text is too difficult\n",
      "has many basic sight words, content words (weather, california) and  patterns\n",
      "recognizes sight words and most high frequency words\n",
      "reading initial sounds, but not reading through entire word\n",
      "errors probably affect comprehension\n",
      "uses initial letters to guess at unknown words\n",
      "attends to the beginnings of words\n",
      "some difficulty with multisyllabic words (i.e. inventation)\n",
      "insertions of minor words\n",
      "strong phonics knowledge\n",
      "rushed through the reading\n",
      "faster reading rate\n",
      "sometimes unstressed syllables in multisyllable words are slurred (saturday, anxiously, several)\n",
      "sometimes speed affects enunciation\n",
      "takes apart multisyllabic words\n",
      "seems to be on right level\n",
      "does not enunciate\n",
      "evidence of taking apart two-syllable words\n",
      "successfully reads past tense verbs (-ed endings)\n",
      "student reading quickly\n",
      "student removing ending of words '-ed'\n",
      "student correcting insertions 'the'\n",
      "reads too fast for comprehension to be intact\n",
      "replaced certain sight/high-frequency words with others (off/of, the/a)\n",
      "good pace\n",
      "familiar with some basic sight words\n",
      "demonstrates an awareness of sentences\n",
      "has many beginning and ending sounds\n",
      "difficult text for reader\n",
      "basic sight words not known\n",
      "guesses at words\n",
      "difficulty taking apart words\n",
      "student struggles with vowel patterns and some r-controlled vowels\n",
      "text is challenging\n",
      "difficult text for reader\n",
      "passage too hard\n",
      "familiar with sigh words and many high frequency words\n",
      "student changing pitch when reading questions\n",
      "reads at an adequate rate\n",
      "good control of r-controlled vowels\n",
      "some evidence of control of initial consonant blends\n",
      "$obs\n",
      "inserts additional words into sentences like \"the\"\n",
      "difficulty with the phoneme ph-\n",
      "evidence of taking apart multisyllabic words (semaphores)\n",
      "some words repeated\n",
      "careful reader\n",
      "some difficulty with prefixes and suffixes\n",
      "reads at good rate\n",
      "several insertions of connecting words\n",
      "reads what he thinks would make sense in the sentence, but not what is on the page\n",
      "evidence of taking apart multisyllabic words (hydroponic, submerged)\n",
      "does not carefully attend to visual information\n",
      "reads too quickly\n",
      "text appears too easy for this reader\n",
      "reads a bit too rapidly at points, which may (or may not) indicate that student is not comprehending\n",
      "student reading quickly\n",
      "student inconsistently pausing for commas\n",
      "student pausing when listing words\n",
      "at times does not fully attend to visual information\n",
      "speeds up reading rate in the middle of passage\n",
      "reads through most commas without pausing\n",
      "text very difficult for this student so comprehension may not be there\n",
      "rushed at the end of the passage to finish the sentence\n",
      "text level likely too difficult for student\n",
      "uneven reading rate\n",
      "passage is a level or two high for student\n",
      "student reads beginnings, but is not reading through entire words\n",
      "provide instruction in medial vowel patterns, r-controlled vowel\n",
      "able to take apart compound words (something, slackline)\n",
      "occasionally runs over periods\n",
      "recognizes most sight words and high-frequency words\n",
      "passage is too difficult for student\n",
      "difficult text\n",
      "guessing at words based on initial letters of words\n",
      "loses momentum toward the end\n",
      "student pausing in between sentences inconsistently\n",
      "inserts short words (the, a)\n",
      "limited subject knowledge\n",
      "text too difficult for student\n",
      "consonant and vowel sounds were often incorrect\n",
      "passage too hard\n",
      "reading letter names instead of letter sounds\n",
      "reading unintelligible\n",
      "over-relying on sight words (of, to, the)\n",
      "text too difficult\n",
      "laborious\n",
      "reads in syllables, not blended into words\n",
      "knows a few high frequency words (of, the)\n",
      "second language learner\n",
      "[how did student even get this text?]\n",
      "student not pausing between sentences\n",
      "reads too fast\n",
      "does not read whole passage aloud\n",
      "reads known words rapidly\n",
      "some vowel confusion with short/long vowel sounds\n",
      "some emphasis on the wrong words within a sentence made the sentences sound disjointed\n",
      "left off the -y in photography\n",
      "enunciates well\n",
      "reads a bit too rapidly at times which may indicate a breakdown of comprehension\n",
      "does not consistently stop to correct errors\n",
      "stammers a bit on several words\n",
      "sometimes difficult to understand due to mumbling through the difficult words\n",
      "mumbles when encountering difficult words\n",
      "takes apart two-syllable words and compound words\n",
      "good command of sight words\n",
      "difficulty with tracking\n",
      "lost place in text\n",
      "some evidence of taking apart words (polished, activity)\n",
      "rate inconsistent\n",
      "trouble with long vowel sounds (cement, plywood, recreation)\n",
      "appears to be on level, check on comprehension\n",
      "drops endings (frame instead of framing)\n",
      "good strategies for taking apart multisyllabic words\n",
      "good rate and volume\n",
      "reading is somewhat choppy\n",
      "difficulty with multisyllabic words\n",
      "student reading quickly\n",
      "student pausing when listing words\n",
      "student repeating certain words at the end of a sentence\n",
      "difficult to understand, mumbles\n",
      "adequate pace\n",
      "evidence of taking apart multisyllabic words (hydroponic)\n",
      "student placing emphasis on signal words\n",
      "student pacing is appropriate\n",
      "doesn't always attend to word endings\n",
      "good self-monitoring\n",
      "passage is at student's instructional level\n",
      "evidence of past tense verb knowledge\n",
      "difficulty taking apart multisyllabic words (specific, accomplish, photography)\n",
      "reads sight many words and high frequency words\n",
      "struggles with some vowel patterns\n",
      "text is slightly difficult\n",
      "hoarse voice quality\n",
      "student reading quickly\n",
      "student repeating words as they read\n",
      "familiar with many sight words and high-frequency words\n",
      "text is too challenging for student\n",
      "passage too difficult\n",
      "not flexible with taking words apart\n",
      "attends to initial sound\n",
      "little background knowledge about topic\n",
      "difficult text\n",
      "student reading carefully\n",
      "does not attend to word endings\n",
      "seems good at blending after sounding out words\n",
      "student reading very quickly\n",
      "student repeating words when first forgetting to include ending\n",
      "reads quite rapidly\n",
      "demonstrates ability to take apart words on the fly\n",
      "r-less in consonant blends and post-vocalically\n",
      "difficulty articulating /r/ sound\n",
      "student rereading portions of the text for clarification\n",
      "good reading rate\n",
      "evidence of searching behaviors\n",
      "controls possessives\n",
      "good self-monitoring skills\n",
      "reads quickly\n",
      "difficulty with suffixes (-ly)\n",
      "starts strong and then fades at end\n",
      "difficulty with some endings/suffixes of words\n",
      "self-monitors and corrects most errors\n",
      "difficulty solving multisyllabic words with emphasis on correct syllable\n",
      "student reading very quickly\n",
      "student not pausing long enough in between sentences\n",
      "student inserting words 'the'\n",
      "reads too fast\n",
      "lacks familiarity with irregular past tense verbs (caught)\n",
      "strong reader\n",
      "reads quickly\n",
      "elides unstressed syllable (can provide fish)\n",
      "evidence of taking apart two-syllable and compound words\n",
      "able to read past a word and then come back to it to solve it with context\n",
      "struggles with some vowel patterns (ex: through, sparkling)\n",
      "does not always monitor syntax\n",
      "familiar with some basic sight words\n",
      "demonstrates an awareness of sentences\n",
      "has many beginning and ending sounds\n",
      "attending to beginning sounds, but not the entire word when encountering a tricky word\n",
      "past tense errors\n",
      "seems to potentially be using a picture to determine some words but unclear\n",
      "difficulty with initial sounds\n",
      "difficulty with long vowel sounds and vowel teams\n",
      "does not always attend to word endings\n",
      "limited data as student did not read much out loud, stopping when encountering tricky words and scanning ahead in the text for something familiar\n",
      "familiar with some beginning and ending sounds, some sight words and high frequency words\n",
      "passage too hard\n",
      "confuses short vowels\n",
      "little stamina\n",
      "some sight word knowledge\n",
      "attends to initial consonant sounds\n",
      "subvocalizes during word solving\n",
      "little experience with taking apart two-syllable words\n",
      "text is too difficult\n",
      "familiar with basic sight words\n",
      "demonstrates an awareness of sentences\n",
      "not attending to some endings and medial vowels\n",
      "text is challenging for reader\n",
      "difficulty with long vowel sounds\n",
      "difficulty with multisyllabic words\n",
      "observes some periods\n",
      "familiar with many sight words and high-frequency words\n",
      "confusion with pronouns\n",
      "some evidence of taking apart words\n",
      "text level seems appropriate\n",
      "demonstrates knowledge of possessives and contractions\n",
      "reads in a choppy manner\n",
      "good reader\n",
      "not attending to endings of words\n",
      "limited data--started late and stopped in the middle of the passage\n",
      "less than half text read\n",
      "does not demonstrate flexibility with taking apart words\n",
      "has difficulty reading possessives\n",
      "passage is too difficult for student\n",
      "finds and reads a few familiar words without successfully articulating any sentences\n",
      "text is too difficult\n",
      "guesses at words\n",
      "attempts few words\n",
      "reading is unintelligible\n",
      "passage is too difficult\n",
      "familiar with many high frequency words and sight words\n",
      "rate and volume inconsistent\n",
      "does not always cross-check multiple sources of information\n",
      "solid sight word knowledge\n"
     ]
    }
   ],
   "source": [
    "filter_(\n",
    "    [\n",
    "        'expressi',\n",
    "        'fluen',\n",
    "        'phras',\n",
    "        'word by',\n",
    "        'word-by',\n",
    "        'intona',\n",
    "        'self-correct',\n",
    "        'self correct',\n",
    "        'accura',\n",
    "        'punctua',\n",
    "        'meaning',\n",
    "        'substitut',\n",
    "        'skip',\n",
    "        'miscu',\n",
    "        'vocabul',\n",
    "        'quiet',\n",
    "        'slow',\n",
    "        'decod',\n",
    "        'omit',\n",
    "        'omission',\n",
    "        'pronounc',\n",
    "        'pronunc',\n",
    "        'attack',\n",
    "        'mis',\n",
    "        'monotone'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing lda code (from priva-dwivedi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize and lemmatize\n",
    "def preprocess(text):\n",
    "    result=[]\n",
    "    for token in gensim.utils.simple_preprocess(text) :\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_docs = []\n",
    "\n",
    "for doc in corpus:\n",
    "    processed_docs.append(preprocess(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 independ\n",
      "1 level\n",
      "2 passag\n",
      "3 read\n",
      "4 accur\n",
      "5 adequ\n",
      "6 express\n",
      "7 speed\n",
      "8 student\n",
      "9 usual\n",
      "10 attend\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_num = 1\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "# for i in range(len(bow_doc_x)):\n",
    "#     print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "#                                                      dictionary[bow_doc_x[i][0]], \n",
    "#                                                      bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 8, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.165*\"student\" + 0.110*\"read\" + 0.049*\"paus\" + 0.041*\"sentenc\" + 0.033*\"quick\" + 0.021*\"text\" + 0.020*\"check\" + 0.019*\"word\" + 0.019*\"inform\" + 0.017*\"inconsist\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.114*\"word\" + 0.084*\"sight\" + 0.075*\"mean\" + 0.053*\"high\" + 0.047*\"frequenc\" + 0.035*\"maintain\" + 0.030*\"monoton\" + 0.027*\"reread\" + 0.027*\"read\" + 0.024*\"visual\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.177*\"express\" + 0.118*\"read\" + 0.076*\"good\" + 0.040*\"limit\" + 0.039*\"littl\" + 0.039*\"inton\" + 0.037*\"accur\" + 0.035*\"reader\" + 0.023*\"rate\" + 0.019*\"adequ\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.260*\"word\" + 0.056*\"read\" + 0.047*\"substitut\" + 0.031*\"student\" + 0.030*\"insert\" + 0.028*\"evid\" + 0.028*\"multisyllab\" + 0.028*\"mean\" + 0.020*\"apart\" + 0.018*\"interfer\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.147*\"word\" + 0.064*\"sound\" + 0.049*\"decod\" + 0.046*\"end\" + 0.042*\"omit\" + 0.030*\"difficulti\" + 0.023*\"vowel\" + 0.021*\"initi\" + 0.020*\"attend\" + 0.017*\"begin\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.167*\"phrase\" + 0.113*\"read\" + 0.077*\"word\" + 0.054*\"long\" + 0.046*\"short\" + 0.044*\"express\" + 0.039*\"difficult\" + 0.037*\"text\" + 0.021*\"sentenc\" + 0.021*\"good\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.138*\"correct\" + 0.132*\"self\" + 0.127*\"mean\" + 0.113*\"miscu\" + 0.054*\"monitor\" + 0.030*\"passag\" + 0.027*\"error\" + 0.024*\"reread\" + 0.020*\"maintain\" + 0.019*\"interfer\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.241*\"punctuat\" + 0.108*\"attend\" + 0.071*\"observ\" + 0.037*\"strong\" + 0.029*\"read\" + 0.028*\"vocabulari\" + 0.023*\"guess\" + 0.021*\"knowledg\" + 0.020*\"letter\" + 0.019*\"inton\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
