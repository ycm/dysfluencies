{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create more features.\n",
    "\n",
    "The code below has not been optimized so some calculations are unnecessarily repeated. Because of the small training set size, the runtime is mostly negligible anyways. Should these features be recreated, detailed documentation is located in `dysfluencies/pipeline/more_features.md`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, json, difflib\n",
    "sys.path.append('/Users/ycm/Desktop/dysfluencies/pipeline/util/')\n",
    "import condense_new\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/features_and_labels_by_example/features_by_ex_NormalizedTokenScores_WithReaderID.tsv') as f:\n",
    "    features = [x.strip() for x in f.readlines()]\n",
    "# labels = pd.read_csv('res/features_and_labels_by_example/labels_by_ex_NormalizedTokenScores_WithReaderID.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_resources = [\n",
    "    'res/reader_to_item.json',\n",
    "    'res/reader_to_alignment.json',\n",
    "    'res/gold_passage_id_to_sessions_to_alignments.json'\n",
    "]\n",
    "rs = []\n",
    "for r in json_resources:\n",
    "    with open(r) as f:\n",
    "        rs.append(json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_to_item,\\\n",
    "reader_to_alignment,\\\n",
    "passage_id_to_session_to_gold_alignments = rs\n",
    "passage_id_to_session_to_gold_alignments = {\n",
    "    int(k): v\n",
    "    for k, v in passage_id_to_session_to_gold_alignments.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 70, 27)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reader_to_item), len(reader_to_alignment), len(passage_id_to_session_to_gold_alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_gold(token):\n",
    "    return token[:2] == '  ' or token[:2] == '+ '\n",
    "def in_ex(token):\n",
    "    return token[:2] == '  ' or token[:2] == '- '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_sequence(c_seq, g_seq):\n",
    "    # '+ ' -> gold token missed\n",
    "    # '- ' -> incorrect insertion\n",
    "    seq1_delim = [x[0] for x in c_seq]\n",
    "    seq2_delim = [x[0] for x in g_seq]\n",
    "    \n",
    "    diff = [x for x in difflib.ndiff(seq1_delim, seq2_delim) if x[0] != '?']\n",
    "    ex_tokens = [x for x in diff if in_ex(x)]\n",
    "    gold_tokens = [x for x in diff if in_gold(x)]\n",
    "    \n",
    "    assert len(ex_tokens) == len(c_seq) and len(gold_tokens) == len(g_seq)\n",
    "    \n",
    "    ex_iter = (x for x in c_seq)\n",
    "    gold_iter = (x for x in g_seq)\n",
    "    \n",
    "    # create <pause> separated phrases in gold alignment\n",
    "    gold_pause_sep = [[]]\n",
    "    for token in diff:\n",
    "        if in_gold(token):\n",
    "            curr_token = next(gold_iter)\n",
    "            if token[2:] == '<pause>':\n",
    "                gold_pause_sep[-1].append(curr_token)\n",
    "                gold_pause_sep.append([])\n",
    "            else:\n",
    "                gold_pause_sep[-1].append(curr_token)\n",
    "                \n",
    "    n_gold_groupings = len(gold_pause_sep)\n",
    "    ex_pause_sep = [[] for _ in range(n_gold_groupings)]\n",
    "    curr_group_idx = 0\n",
    "    for token in diff:\n",
    "        if in_ex(token):\n",
    "            curr_token = next(ex_iter)\n",
    "            ex_pause_sep[curr_group_idx].append(curr_token)\n",
    "        if in_gold(token) and token[2:] == '<pause>':\n",
    "            curr_group_idx += 1\n",
    "            continue\n",
    "\n",
    "#     for ex_terms, gold_terms in zip(ex_pause_sep, gold_pause_sep):\n",
    "#         print('\\t'.join([x[0] for x in ex_terms]))\n",
    "#         print('\\t'.join([x[0] for x in gold_terms]))\n",
    "#         print()\n",
    "    \n",
    "    return ex_pause_sep, gold_pause_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(l1, l2):\n",
    "    return 1 - spatial.distance.cosine(l1, l2)\n",
    "\n",
    "def jaccard(l1, l2):\n",
    "    ''' Unused '''\n",
    "    s1, s2 = set(l1), set(l2)\n",
    "    return len(s1 & s2) / len(s1 | s2)\n",
    "\n",
    "def get_avg_f0(alignment):\n",
    "    f0s = [\n",
    "        f0\n",
    "        for term in alignment\n",
    "        for f0 in eval(term[3])\n",
    "    ]\n",
    "    return sum(f0s) / len(f0s)\n",
    "\n",
    "def slope(f0s):\n",
    "    return (f0s[-1] - f0s[0]) / len(f0s) \n",
    "\n",
    "def compute_f0_match_score(matched_ex, matched_gold, avg_ex_f0, avg_gold_f0):\n",
    "    '''\n",
    "    Computes F0-related scores for a pair of groups\n",
    "    '''\n",
    "    ex_slopes = []\n",
    "    gold_slopes = []\n",
    "    for ex_term, gold_term in zip(matched_ex, matched_gold):\n",
    "        ex_f0s = [x - avg_ex_f0 for x in eval(ex_term[3])]\n",
    "        gold_f0s = [x - avg_gold_f0 for x in eval(gold_term[3])]\n",
    "        ex_slopes.append(slope(ex_f0s))\n",
    "        gold_slopes.append(slope(gold_f0s))\n",
    "\n",
    "    rv = cosine(ex_slopes, gold_slopes)\n",
    "    if rv != rv: # rv == nan\n",
    "        rv = 0\n",
    "    return rv\n",
    "        \n",
    "\n",
    "def compute_single_group_scores(ex_group, gold_group, avg_ex_f0, avg_gold_f0):\n",
    "    '''\n",
    "    Computes similarity scores between a single gold GROUP\n",
    "    (<pause>-delimited) and its corresponding example group\n",
    "    '''\n",
    "    seq1_delim = [x[0] for x in ex_group]\n",
    "    seq2_delim = [x[0] for x in gold_group]\n",
    "    \n",
    "    diff = [x for x in difflib.ndiff(seq1_delim, seq2_delim) if x[0] != '?']\n",
    "    ex_tokens = [x for x in diff if in_ex(x)]\n",
    "    gold_tokens = [x for x in diff if in_gold(x)]\n",
    "    \n",
    "    iter_ex = (x for x in ex_group)\n",
    "    iter_gold = (x for x in gold_group)\n",
    "    \n",
    "    matched_ex = []\n",
    "    matched_gold = []\n",
    "    for token in diff:\n",
    "        if not in_ex(token):\n",
    "            next(iter_gold)\n",
    "        elif not in_gold(token):\n",
    "            next(iter_ex)\n",
    "        elif '<pause>' in token:\n",
    "            continue\n",
    "        else:\n",
    "            matched_ex.append(next(iter_ex))\n",
    "            matched_gold.append(next(iter_gold))\n",
    "    \n",
    "    n_pauses_inserted = diff.count('- <pause>')\n",
    "    n_pauses_omitted = diff.count('+ <pause>')\n",
    "    \n",
    "    if matched_ex:\n",
    "        ex_group_nframes = [x[2] for x in matched_ex]\n",
    "        gold_group_nframes = [x[2] for x in matched_gold]\n",
    "        nframes_similarity = cosine(ex_group_nframes, gold_group_nframes)\n",
    "        matched_tokens_similarity = len(matched_ex) / len(gold_group)\n",
    "        curr_group_dur_sim = nframes_similarity * matched_tokens_similarity\n",
    "        \n",
    "        f0_match_score = compute_f0_match_score(\n",
    "            matched_ex,\n",
    "            matched_gold,\n",
    "            avg_ex_f0,\n",
    "            avg_gold_f0\n",
    "        )\n",
    "        \n",
    "        curr_group_f0_sim = f0_match_score * matched_tokens_similarity\n",
    "    else:\n",
    "        curr_group_dur_sim = 0\n",
    "        curr_group_f0_sim = 0\n",
    "    \n",
    "    return curr_group_dur_sim, curr_group_f0_sim, n_pauses_inserted, n_pauses_omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_group_based_features(ex_pause_sep, gold_pause_sep, avg_ex_f0, avg_gold_f0):\n",
    "    gold_len = sum(len(x) for x in gold_pause_sep)\n",
    "    \n",
    "    n_pauses_in_gold = [y[0] for x in gold_pause_sep for y in x].count('<pause>')\n",
    "    pauses_inserted = 0\n",
    "    pauses_omitted = 0\n",
    "    \n",
    "    \n",
    "    group_duration_sim = []\n",
    "    weighted_group_duration_sim = 0\n",
    "    \n",
    "    group_f0_sim = []\n",
    "    weighted_group_f0_sim = 0\n",
    "    \n",
    "    for ex_terms, gold_terms in zip(ex_pause_sep, gold_pause_sep):\n",
    "        duration_score, f0_score, n_pauses_inserted, n_pauses_omitted = compute_single_group_scores(\n",
    "            ex_terms,\n",
    "            gold_terms,\n",
    "            avg_ex_f0,\n",
    "            avg_gold_f0\n",
    "        )\n",
    "        \n",
    "        group_duration_sim.append(duration_score)\n",
    "        weighted_group_duration_sim += duration_score * len(gold_terms) / gold_len\n",
    "        \n",
    "        group_f0_sim.append(f0_score)\n",
    "        weighted_group_f0_sim += f0_score * len(gold_terms) / gold_len\n",
    "        \n",
    "        pauses_inserted += n_pauses_inserted\n",
    "        pauses_omitted += n_pauses_omitted\n",
    "    \n",
    "    group_duration_sim = sum(group_duration_sim) / len(group_duration_sim)\n",
    "    group_f0_sim = sum(group_f0_sim) / len(group_f0_sim)\n",
    "    \n",
    "    normalized_pauses_inserted = pauses_inserted / n_pauses_in_gold\n",
    "    normalized_pauses_omitted = pauses_omitted / n_pauses_in_gold\n",
    "    \n",
    "    return group_duration_sim,\\\n",
    "        weighted_group_duration_sim,\\\n",
    "        group_f0_sim,\\\n",
    "        weighted_group_f0_sim,\\\n",
    "        normalized_pauses_inserted,\\\n",
    "        normalized_pauses_omitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ycm/miniconda3/lib/python3.7/site-packages/scipy/spatial/distance.py:702: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "reader_to_additional_features = {}\n",
    "for reader, alignment in reader_to_alignment.items():\n",
    "    passage_id = reader_to_item[reader]\n",
    "    c_stripped = condense_new.strip_pauses(alignment)\n",
    "    c_combined_pauses = condense_new.combine_adjacent_pauses(c_stripped)\n",
    "    c_condensed = condense_new.collapse_pauses(c_combined_pauses)\n",
    "    \n",
    "    avg_c_f0 = get_avg_f0(c_condensed)\n",
    "    \n",
    "    assert condense_new.is_valid(c_stripped) and condense_new.is_valid(c_condensed)\n",
    "    \n",
    "    # get gold alignment for current items\n",
    "    gold_alignments = passage_id_to_session_to_gold_alignments[passage_id].values()\n",
    "    \n",
    "    group_based_feature_list = []\n",
    "    for g_alignment in gold_alignments:\n",
    "        g_stripped = condense_new.strip_pauses(g_alignment)\n",
    "        g_combined_pauses = condense_new.combine_adjacent_pauses(g_stripped)\n",
    "        g_condensed = condense_new.collapse_pauses(g_combined_pauses)\n",
    "        assert condense_new.is_valid(g_stripped) and condense_new.is_valid(g_condensed)\n",
    "        \n",
    "        avg_g_f0 = get_avg_f0(g_condensed)\n",
    "        ex_pause_sep, gold_pause_sep = align_sequence(c_stripped, g_stripped)\n",
    "        group_based_feature_list.append(compute_group_based_features(\n",
    "            ex_pause_sep,\n",
    "            gold_pause_sep,\n",
    "            avg_c_f0,\n",
    "            avg_g_f0\n",
    "        ))\n",
    "        \n",
    "#         break\n",
    "    averaged_features = ([\n",
    "        sum(x) / len(group_based_feature_list)\n",
    "        for x in zip(*group_based_feature_list)\n",
    "    ])\n",
    "\n",
    "#     GroupDurationSim,\\\n",
    "#     WeightedGroupDurationSim,\\\n",
    "#     GroupF0Sim,\\\n",
    "#     WeightedGroupF0Sim,\\\n",
    "#     NormalizedPausesInserted,\\\n",
    "#     NormalizedPausesOmitted = averaged_features\n",
    "    \n",
    "    reader_to_additional_features[reader] = averaged_features\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reader_to_additional_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_features = ['\\t'.join([\n",
    "    features[0],\n",
    "    'GroupDurationSim',\n",
    "    'WeightedGroupDurationSim',\n",
    "    'GroupF0Sim',\n",
    "    'WeightedGroupF0Sim',\n",
    "    'NormalizedPausesInserted',\n",
    "    'NormalizedPausesOmitted'\n",
    "])]\n",
    "\n",
    "for line in features[1:]:\n",
    "    reader_id = (line.split('\\t')[0])\n",
    "    additional_features = reader_to_additional_features[reader_id]\n",
    "    extended_features.append(line + '\\t' + '\\t'.join([str(x) for x in additional_features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('res/features_and_labels_by_example/features_by_ex_NormalizedTokenScores_WithReaderID_WithAdditionalFeatures.tsv', 'w') as f:\n",
    "#     for line in extended_features:\n",
    "#         print(line, file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
